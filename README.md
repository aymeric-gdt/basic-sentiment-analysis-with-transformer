# Exploration de l'Analyse de Sentiment avec un Transformer

Un projet √©ducatif pour comprendre et impl√©menter l'architecture Transformer de z√©ro, appliqu√©e √† la classification d'√©motions dans des tweets.

## üìö Objectif et D√©marche

Ce projet a √©t√© con√ßu comme une **d√©marche d'apprentissage** pour d√©couvrir l'architecture Transformer, popularis√©e par le papier ["Attention Is All You Need"](https://arxiv.org/abs/1706.03762) de Vaswani et al. (2017). 

### Pourquoi ce projet ?

L'objectif √©tait de :
- **Comprendre les m√©canismes fondamentaux** des Transformers (attention multi-t√™tes, encodage positionnel, etc.)
- **Impl√©menter de z√©ro** chaque composant plut√¥t que d'utiliser des biblioth√®ques pr√©-construites
- **Appliquer concr√®tement** ces concepts √† un probl√®me r√©el : la classification d'√©motions
- **Visualiser et analyser** les performances du mod√®le

### Parcours d'apprentissage

1. **Compr√©hension th√©orique** : √âtude de l'architecture Transformer et de ses composants
2. **Impl√©mentation** : Construction progressive de chaque couche (embeddings, attention, feed-forward, etc.)
3. **Entra√Ænement** : Mise en place du pipeline d'entra√Ænement avec validation
4. **√âvaluation** : Analyse d√©taill√©e des performances par classe d'√©motion
5. **Application** : Cr√©ation d'une interface de pr√©diction pour tester le mod√®le

## üèóÔ∏è Architecture du Mod√®le

Le mod√®le impl√©ment√© suit l'architecture Transformer classique avec les composants suivants :

### Composants principaux

1. **Token Embedding** : Conversion des tokens en vecteurs de dimension `embed_dim`
2. **Positional Encoding** : Encodage positionnel sinuso√Ødal pour capturer l'ordre des mots
3. **Multi-Head Attention** : M√©canisme d'attention avec `num_heads` t√™tes parall√®les
4. **Feed-Forward Network** : R√©seau feed-forward avec activation GELU
5. **Encoder Blocks** : Empilement de `num_layers` blocs encodeurs
6. **Classification Head** : Couche lin√©aire finale pour la classification en 6 classes

### Param√®tres du mod√®le

```python
vocab_size = 10000      # Taille du vocabulaire
embed_dim = 512         # Dimension des embeddings
num_heads = 8           # Nombre de t√™tes d'attention
ff_dim = 2048           # Dimension du r√©seau feed-forward
num_layers = 4          # Nombre de blocs d'encodeur
max_length = 256        # Longueur maximale des s√©quences
num_classes = 6         # Nombre de classes d'√©motions
dropout = 0.1           # Taux de dropout
```

**Note importante** : `embed_dim` doit √™tre divisible par `num_heads` pour que l'attention multi-t√™tes fonctionne correctement.

## üìä Dataset

Le projet utilise le dataset [**dair-ai/emotion**](https://huggingface.co/datasets/dair-ai/emotion) de HuggingFace, qui contient des tweets annot√©s avec 6 √©motions :

- **0** : sadness (tristesse)
- **1** : joy (joie)
- **2** : love (amour)
- **3** : anger (col√®re)
- **4** : fear (peur)
- **5** : surprise (surprise)

**Statistiques du dataset** :
- **Train** : 16 000 √©chantillons
- **Validation** : 2 000 √©chantillons
- **Test** : 2 000 √©chantillons

### Pr√©processing

Les textes sont nettoy√©s pour :
- Supprimer les URLs
- Normaliser les accents (unidecode)
- Supprimer les mentions (@username) et hashtags (#tag)
- Supprimer les caract√®res sp√©ciaux

## üöÄ Utilisation

### Installation

```bash
# Installer les d√©pendances avec uv (ou pip)
uv sync
```

### Entra√Ænement du mod√®le

```bash
python -m src.train
```

Le script va :
- Construire le vocabulaire √† partir des donn√©es d'entra√Ænement
- Cr√©er les DataLoaders pour train/validation/test
- Entra√Æner le mod√®le sur 20 √©poques
- Sauvegarder le meilleur mod√®le dans `checkpoints/best_model.pt`
- Sauvegarder le tokenizer dans `checkpoints/tokenizer.pt`

### √âvaluation du mod√®le

```bash
python -m src.evaluate
```

Ce script g√©n√®re :
- Un rapport de classification d√©taill√©
- Des m√©triques par label (pr√©cision, rappel, F1-score)
- Des visualisations dans le dossier `results/` (√©galement visibles dans la section [R√©sultats](#-r√©sultats) ci-dessous) :
  - `precision_by_label.png` : Pr√©cision par √©motion
  - `confusion_matrix.png` : Matrice de confusion
  - `metrics_by_label.png` : Comparaison pr√©cision/rappel/F1

### Pr√©diction sur un texte

**Mode interactif** :
```bash
python -m src.predict
```

**Avec argument** :
```bash
python -m src.predict "I am so happy today!"
```

Le script affiche :
- L'√©motion pr√©dite
- Les probabilit√©s pour toutes les classes
- Un graphique des probabilit√©s

## üìà R√©sultats

### Performance globale

Le mod√®le atteint une **accuracy de validation** qui varie selon les hyperparam√®tres utilis√©s. Les r√©sultats d√©taill√©s sont disponibles dans les graphiques g√©n√©r√©s par `evaluate.py`.

### M√©triques par classe

Les visualisations ci-dessous montrent les performances d√©taill√©es du mod√®le :

#### Pr√©cision par Label

![Pr√©cision par Label](results/precision_by_label.png)

Ce graphique montre la **pr√©cision** (capacit√© du mod√®le √† ne pas faire de faux positifs) pour chaque √©motion. Les valeurs affich√©es au-dessus des barres indiquent la pr√©cision et le nombre d'√©chantillons (support) pour chaque classe.

#### Matrice de Confusion

![Matrice de Confusion](results/confusion_matrix.png)

La matrice de confusion r√©v√®le les **confusions fr√©quentes** entre classes. Les valeurs sur la diagonale repr√©sentent les pr√©dictions correctes, tandis que les valeurs hors diagonale indiquent les erreurs de classification.

#### M√©triques Compl√®tes (Pr√©cision, Rappel, F1-Score)

![M√©triques par Label](results/metrics_by_label.png)

Cette visualisation compare trois m√©triques importantes pour chaque √©motion :
- **Pr√©cision** : Capacit√© du mod√®le √† ne pas faire de faux positifs
- **Rappel** : Capacit√© du mod√®le √† trouver tous les vrais positifs
- **F1-Score** : Moyenne harmonique de la pr√©cision et du rappel

### Analyse des r√©sultats

Les graphiques permettent d'identifier :
- Les √©motions les mieux class√©es par le mod√®le
- Les confusions fr√©quentes entre classes (via la matrice de confusion)
- Les classes potentiellement sous-repr√©sent√©es dans le dataset
- Les m√©triques qui n√©cessitent une am√©lioration (faible rappel ou pr√©cision)

## üß† Concepts Appris

### 1. Attention Multi-T√™tes

L'attention permet au mod√®le de se concentrer sur diff√©rentes parties de la s√©quence simultan√©ment. Avec plusieurs t√™tes, le mod√®le peut capturer diff√©rents types de relations.

### 2. Encodage Positionnel

Contrairement aux RNN, les Transformers n'ont pas de notion inn√©e d'ordre. L'encodage positionnel sinuso√Ødal ajoute cette information aux embeddings.

### 3. Architecture Encoder-Only

Pour la classification, seule la partie encodeur est n√©cessaire. Le mod√®le transforme la s√©quence en repr√©sentation puis fait un pooling pour la classification.

### 4. Masques d'Attention

Les masques permettent d'ignorer les tokens de padding, essentiel pour g√©rer des s√©quences de longueurs variables.

## üìÅ Structure du Projet

```
basic-sentiment-analysis-with-transformer/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ model.py          # Architecture Transformer compl√®te
‚îÇ   ‚îú‚îÄ‚îÄ data.py           # Chargement et preprocessing des donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.py      # Tokenizer simple bas√© sur les mots
‚îÇ   ‚îú‚îÄ‚îÄ train.py          # Script d'entra√Ænement
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py       # Script d'√©valuation avec visualisations
‚îÇ   ‚îî‚îÄ‚îÄ predict.py        # Script de pr√©diction interactive
‚îú‚îÄ‚îÄ checkpoints/          # Mod√®les sauvegard√©s
‚îú‚îÄ‚îÄ results/              # Graphiques d'√©valuation
‚îî‚îÄ‚îÄ README.md
```

## üîß D√©pendances

- `torch` : Framework de deep learning
- `datasets` : Chargement du dataset HuggingFace
- `matplotlib` & `seaborn` : Visualisations
- `scikit-learn` : M√©triques d'√©valuation
- `tqdm` : Barres de progression
- `unidecode` : Normalisation des caract√®res

## üéØ Prochaines √âtapes Possibles

- [ ] Exp√©rimentation avec diff√©rents hyperparam√®tres
- [ ] Comparaison avec des mod√®les pr√©-entra√Æn√©s (BERT, RoBERTa)
- [ ] Analyse de l'attention (visualisation des poids d'attention)
- [ ] Fine-tuning sur un dataset sp√©cifique
- [ ] D√©ploiement en API REST

## üìù Notes

Ce projet est avant tout **√©ducatif**. Pour des applications en production, il est recommand√© d'utiliser des mod√®les pr√©-entra√Æn√©s comme BERT ou des architectures plus r√©centes, qui b√©n√©ficient de l'entra√Ænement sur de vastes corpus.

## üìÑ Licence

Ce projet est √† des fins √©ducatives.

---

**Auteur** : Exploration personnelle des Transformers  
**Date** : 2025
